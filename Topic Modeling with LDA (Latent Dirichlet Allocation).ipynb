{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4928d8b9-c4a8-4854-b2f3-4b8f03e56da9",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">Lab Assignment 4: Text Classification with Deep Learning</h2>\r\n",
    " \n",
    "\n",
    "**AUTHOR NAME : BALBIR SINGH**\n",
    "\n",
    "**ASU ID :1233870107** \n",
    "\n",
    "**FILE CREATION DATE  :2/20/2025**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c497ea24-b158-442a-b861-968d0d6aee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: tensorflow in c:\\users\\balbi\\anaconda\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\balbi\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\balbi\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\balbi\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "168aa72e-31ca-4623-881f-c7ef3ef95317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IVS7do_HBzroiCiymNdxDg</td>\n",
       "      <td>fdFgZQQYQJeEAshH4lxSfQ</td>\n",
       "      <td>sGy67CpJctjeCWClWqonjA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OK, the hype about having Hatch chili in your ...</td>\n",
       "      <td>2020-01-27 22:59:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QP2pSzSqpJTMWOCuUuyXkQ</td>\n",
       "      <td>JBLWSXBTKFvJYYiM-FnCOQ</td>\n",
       "      <td>3w7NRntdQ9h0KwDsksIt5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pandemic pit stop to have an ice cream.... onl...</td>\n",
       "      <td>2020-04-19 05:33:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oK0cGYStgDOusZKz9B1qug</td>\n",
       "      <td>2_9fKnXChUjC5xArfF8BLg</td>\n",
       "      <td>OMnPtRGmbY8qH_wIILfYKA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I was lucky enough to go to the soft opening a...</td>\n",
       "      <td>2020-02-29 19:43:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_ABvFCNVLbfOgRg3Pv1KQ</td>\n",
       "      <td>9MExTQ76GSKhxSWnTS901g</td>\n",
       "      <td>V9XlikTxq0My4gE8LULsjw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've gone to claim Jumpers all over the US and...</td>\n",
       "      <td>2020-03-14 21:47:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rd222CrrnXkXukR2iWj69g</td>\n",
       "      <td>LPxuausjvDN88uPr-Q4cQA</td>\n",
       "      <td>CA5BOxKRDPGJgdUQ8OUOpw</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you haven't been  to Maynard's kitchen, it'...</td>\n",
       "      <td>2020-01-17 20:32:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  IVS7do_HBzroiCiymNdxDg  fdFgZQQYQJeEAshH4lxSfQ  sGy67CpJctjeCWClWqonjA   \n",
       "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
       "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
       "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
       "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       1      1     0   \n",
       "1      5       1      1     1   \n",
       "2      5       1      0     0   \n",
       "3      5       0      0     0   \n",
       "4      4       1      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  OK, the hype about having Hatch chili in your ...  2020-01-27 22:59:06  \n",
       "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16  \n",
       "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44  \n",
       "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07  \n",
       "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Cell 1  - Import all the necessary libraries and restaurant review data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "# Load the restaurant review data\n",
    "file_path = \"C:\\\\Users\\\\balbi\\\\Downloads\\\\restaurant_reviews_az.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911e9fb9-f038-4a8f-b322-7a8a5038093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QP2pSzSqpJTMWOCuUuyXkQ</td>\n",
       "      <td>JBLWSXBTKFvJYYiM-FnCOQ</td>\n",
       "      <td>3w7NRntdQ9h0KwDsksIt5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pandemic pit stop to have an ice cream.... onl...</td>\n",
       "      <td>2020-04-19 05:33:16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oK0cGYStgDOusZKz9B1qug</td>\n",
       "      <td>2_9fKnXChUjC5xArfF8BLg</td>\n",
       "      <td>OMnPtRGmbY8qH_wIILfYKA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I was lucky enough to go to the soft opening a...</td>\n",
       "      <td>2020-02-29 19:43:44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_ABvFCNVLbfOgRg3Pv1KQ</td>\n",
       "      <td>9MExTQ76GSKhxSWnTS901g</td>\n",
       "      <td>V9XlikTxq0My4gE8LULsjw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've gone to claim Jumpers all over the US and...</td>\n",
       "      <td>2020-03-14 21:47:07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rd222CrrnXkXukR2iWj69g</td>\n",
       "      <td>LPxuausjvDN88uPr-Q4cQA</td>\n",
       "      <td>CA5BOxKRDPGJgdUQ8OUOpw</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you haven't been  to Maynard's kitchen, it'...</td>\n",
       "      <td>2020-01-17 20:32:57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kx6O_lyLzUnA7Xip5wh2NA</td>\n",
       "      <td>YsINprB2G1DM8qG1hbrPUg</td>\n",
       "      <td>rViAhfKLKmwbhTKROM9m0w</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I stay at the Main Hotel at the Casino from Ju...</td>\n",
       "      <td>2020-07-14 16:43:23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
       "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
       "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
       "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
       "5  kx6O_lyLzUnA7Xip5wh2NA  YsINprB2G1DM8qG1hbrPUg  rViAhfKLKmwbhTKROM9m0w   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "1      5       1      1     1   \n",
       "2      5       1      0     0   \n",
       "3      5       0      0     0   \n",
       "4      4       1      0     0   \n",
       "5      1       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16   \n",
       "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44   \n",
       "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07   \n",
       "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57   \n",
       "5  I stay at the Main Hotel at the Casino from Ju...  2020-07-14 16:43:23   \n",
       "\n",
       "   Sentiment  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Cell 2 (5%) - Remove 3-star reviews and create a Sentiment column.\n",
    "df = df[df['stars'] != 3]  # Remove reviews with 3-star ratings\n",
    "df['Sentiment'] = df['stars'].apply(lambda x: 1 if x >= 4 else 0)  # Assign sentiment labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00026f2f-73cb-489b-bd76-fd965fc225b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35274,), (8819,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Cell 3 (10%) - Data processing and splitting the dataset.\n",
    "X = df['text']  # Assuming the review text column is named 'text'\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display dataset size\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12ecdbcb-4f63-4c68-96ac-161472cfe192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Loaded 400000 word vectors.\n",
      "Unique words in dataset: 33305\n",
      "Embedding matrix prepared successfully.\n"
     ]
    }
   ],
   "source": [
    "#Code Cell 4: Download the pre-trained GloVe word embeddings (glove.6B.100d.txt) and prepare the embedding matrix for this review dataset. \n",
    "\n",
    "# Define paths for GloVe\n",
    "glove_dir = \"C:\\\\Users\\\\balbi\\\\Downloads\"\n",
    "glove_zip_path = os.path.join(glove_dir, \"glove.6B.zip\")\n",
    "glove_text_path = os.path.join(glove_dir, \"glove.6B.100d.txt\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(glove_dir, exist_ok=True)\n",
    "\n",
    "# Download GloVe embeddings if not available\n",
    "if not os.path.exists(glove_text_path):\n",
    "    print(\"Downloading GloVe embeddings...\")\n",
    "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(glove_zip_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            f.write(chunk)\n",
    "\n",
    "    print(\"Download complete. Extracting files...\")\n",
    "\n",
    "    # Extract only the required file\n",
    "    with zipfile.ZipFile(glove_zip_path, \"r\") as zip_ref:\n",
    "        if \"glove.6B.100d.txt\" not in zip_ref.namelist():\n",
    "            raise FileNotFoundError(\"glove.6B.100d.txt not found in the zip file.\")\n",
    "        zip_ref.extract(\"glove.6B.100d.txt\", path=glove_dir)\n",
    "\n",
    "    print(\"Extraction complete.\")\n",
    "\n",
    "# Load the GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "embeddings_index = {}\n",
    "with open(glove_text_path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Loaded {len(embeddings_index)} word vectors.\")\n",
    "\n",
    "# Tokenize the review text\n",
    "MAX_NUM_WORDS = 20000  # Keep only the top 20k words\n",
    "MAX_SEQUENCE_LENGTH = 100  # Max length of each review\n",
    "\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"Column 'text' not found in DataFrame. Ensure the dataset has a 'text' column.\")\n",
    "\n",
    "# Convert all reviews to string (to avoid issues with NaN)\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "# Split data into training and testing sets (80%-20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"Sentiment\"], test_size=0.2, random_state=42, stratify=df[\"Sentiment\"])\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Unique words in dataset: {len(word_index)}\")\n",
    "\n",
    "# Prepare embedding matrix\n",
    "EMBEDDING_DIM = 100\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"Embedding matrix prepared successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4541b84-82c9-4214-9d2e-5f8e3c0e8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balbi\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 172ms/step - accuracy: 0.8087 - loss: 0.4381 - val_accuracy: 0.9275 - val_loss: 0.1862\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 170ms/step - accuracy: 0.9327 - loss: 0.1789 - val_accuracy: 0.9353 - val_loss: 0.1597\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 171ms/step - accuracy: 0.9423 - loss: 0.1533 - val_accuracy: 0.9393 - val_loss: 0.1527\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 172ms/step - accuracy: 0.9530 - loss: 0.1264 - val_accuracy: 0.9494 - val_loss: 0.1395\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 171ms/step - accuracy: 0.9632 - loss: 0.0999 - val_accuracy: 0.9458 - val_loss: 0.1450\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 62ms/step - accuracy: 0.9450 - loss: 0.1483\n",
      "Test Accuracy: 0.9458\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 5  -  Build a GRU model with pre-trained GloVe embedding and show model performance\n",
    "# Define the GRU model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),  # Use pre-trained GloVe embeddings\n",
    "    GRU(128, return_sequences=True),  # First GRU layer with return_sequences=True\n",
    "    Dropout(0.3),\n",
    "    GRU(64),  # Second GRU layer\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")  # Binary classification output (0 or 1 sentiment)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fa07f10-fe8c-4fbb-a961-159553daec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 179ms/step - accuracy: 0.7481 - loss: 0.5275 - val_accuracy: 0.9145 - val_loss: 0.2209\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 179ms/step - accuracy: 0.9158 - loss: 0.2161 - val_accuracy: 0.9283 - val_loss: 0.1818\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 179ms/step - accuracy: 0.9315 - loss: 0.1748 - val_accuracy: 0.9353 - val_loss: 0.1661\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 177ms/step - accuracy: 0.9372 - loss: 0.1636 - val_accuracy: 0.9393 - val_loss: 0.1593\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 98ms/step - accuracy: 0.9408 - loss: 0.1534 - val_accuracy: 0.9355 - val_loss: 0.1630\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9332 - loss: 0.1712\n",
      "LSTM Model Test Accuracy: 0.9355\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 6 (10%) - Build an LSTM model with pre-trained GloVe embedding and show model performance \n",
    "# Define the LSTM model\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),  # Use pre-trained GloVe embeddings\n",
    "    LSTM(128, return_sequences=True),  # First LSTM layer with return_sequences=True\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),  # Second LSTM layer\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")  # Binary classification output (0 or 1 sentiment)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history_lstm = model_lstm.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_lstm.evaluate(X_test_pad, y_test)\n",
    "print(f\"LSTM Model Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4a2868a-6c53-49e1-8a66-fac4f6532d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 93ms/step - accuracy: 0.7963 - loss: 0.4607 - val_accuracy: 0.9367 - val_loss: 0.1699\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 106ms/step - accuracy: 0.9532 - loss: 0.1252 - val_accuracy: 0.9508 - val_loss: 0.1349\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 149ms/step - accuracy: 0.9753 - loss: 0.0719 - val_accuracy: 0.9507 - val_loss: 0.1433\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1449s\u001b[0m 1s/step - accuracy: 0.9880 - loss: 0.0417 - val_accuracy: 0.9475 - val_loss: 0.1761\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 110ms/step - accuracy: 0.9936 - loss: 0.0219 - val_accuracy: 0.9466 - val_loss: 0.2244\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9429 - loss: 0.2383\n",
      "GRU Model with Trainable GloVe Test Accuracy: 0.9466\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 7 - Build a GRU model with trainable GloVe embeddings and show model performance \n",
    "# Define the GRU model with trainable embeddings\n",
    "model_gru_trainable = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=True),  # Trainable GloVe embeddings\n",
    "    GRU(128, return_sequences=True),  # First GRU layer with return_sequences=True\n",
    "    Dropout(0.3),\n",
    "    GRU(64),  # Second GRU layer\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")  # Binary classification output (0 or 1 sentiment)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_gru_trainable.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history_gru_trainable = model_gru_trainable.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_gru_trainable.evaluate(X_test_pad, y_test)\n",
    "print(f\"GRU Model with Trainable GloVe Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5afc8bc-8df0-4c46-8152-45759f551f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 132ms/step - accuracy: 0.7490 - loss: 0.5136 - val_accuracy: 0.9216 - val_loss: 0.2064\n",
      "Epoch 2/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 113ms/step - accuracy: 0.9415 - loss: 0.1642 - val_accuracy: 0.9444 - val_loss: 0.1568\n",
      "Epoch 3/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1384s\u001b[0m 1s/step - accuracy: 0.9682 - loss: 0.0884 - val_accuracy: 0.9429 - val_loss: 0.1406\n",
      "Epoch 4/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 101ms/step - accuracy: 0.9817 - loss: 0.0587 - val_accuracy: 0.9490 - val_loss: 0.1439\n",
      "Epoch 5/5\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 98ms/step - accuracy: 0.9892 - loss: 0.0384 - val_accuracy: 0.9468 - val_loss: 0.1880\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9441 - loss: 0.1992\n",
      "LSTM Model with Trainable GloVe Test Accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 8  - Build an LSTM model with trainable GloVe embeddings and show model performance \n",
    "# Define the LSTM model with trainable embeddings\n",
    "model_lstm_trainable = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=True),  # Trainable GloVe embeddings\n",
    "    LSTM(128, return_sequences=True),  # First LSTM layer with return_sequences=True\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),  # Second LSTM layer\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")  # Binary classification output (0 or 1 sentiment)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_lstm_trainable.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history_lstm_trainable = model_lstm_trainable.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_lstm_trainable.evaluate(X_test_pad, y_test)\n",
    "print(f\"LSTM Model with Trainable GloVe Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1dbc74b-23ea-4cfd-b629-3d329017a231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 35274, Testing samples: 8819\n",
      "SVM (TF-IDF) Test Accuracy: 0.9575\n",
      "SVM (TF-IDF) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      2463\n",
      "           1       0.97      0.97      0.97      6356\n",
      "\n",
      "    accuracy                           0.96      8819\n",
      "   macro avg       0.95      0.94      0.95      8819\n",
      "weighted avg       0.96      0.96      0.96      8819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 9 - Use your best model in your Lab assignment 2 and show the performance \n",
    "# Choose the best model based on previous test accuracies\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "X = df['text']  # Assuming the review text column is named 'text'\n",
    "y = df['Sentiment']  # Assuming the target variable is 'Sentiment'\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display dataset size\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
    "# Step 1: Apply TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Keep top 5000 most frequent words\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)  # Transform training data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)  # Transform testing data\n",
    "\n",
    "# Step 2: Train the Best Model (SVM with TF-IDF)\n",
    "svm_model_tfidf = SVC(kernel='linear')  # Define the SVM model\n",
    "svm_model_tfidf.fit(X_train_tfidf, y_train)  # Train the model on training data\n",
    "\n",
    "# Step 3: Predict on the Test Set\n",
    "y_pred_svm_tfidf = svm_model_tfidf.predict(X_test_tfidf)  # Make predictions on test data\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "test_accuracy = accuracy_score(y_test, y_pred_svm_tfidf)  # Calculate accuracy\n",
    "print(f\"SVM (TF-IDF) Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Display Classification Report\n",
    "print(\"SVM (TF-IDF) Performance:\")\n",
    "print(classification_report(y_test, y_pred_svm_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a490d4-cf40-4f15-bea3-1413d2f4fc46",
   "metadata": {},
   "source": [
    "**Text Cell 10: Compare and comment on your observations on the performance of different deep learning models and different embeddings (i.e.,  LSTM and GRU).**\n",
    "In this lab, we compared the performance of different deep learning models (LSTM and GRU) using pre-trained GloVe embeddings in both frozen and trainable settings. Below are the key observations:\n",
    "\n",
    "- **SVM with TF-IDF Achieved the Best Performance**\n",
    "\n",
    "Accuracy: 95.75% (Higher than deep learning models).\n",
    "F1-score: 97% (Class 1) → Consistently high precision & recall.\n",
    "This suggests that traditional ML models with strong text feature extraction (TF-IDF) can outperform deep learning models on structured text datasets.\n",
    "\n",
    "- **GRU and LSTM with Pre-trained GloVe Performed Slightly Worse**\n",
    "Accuracy: ~94%\n",
    "Possible reason: Pre-trained embeddings might not fully capture the dataset’s sentiment-specific language.\n",
    "\n",
    "- **Trainable GloVe Embeddings Improved GRU and LSTM Models Slightly**\n",
    "Accuracy: ~94.5% (GRU slightly better than LSTM)\n",
    "Why? The ability to fine-tune word embeddings allowed the models to adapt better to sentiment classification.\n",
    "\n",
    "- **Deep Learning Models Take More Training Time**\n",
    "SVM (TF-IDF) trains faster than GRU/LSTM since it doesn’t rely on complex sequential computations.\n",
    "GRU/LSTM are better suited for long-text dependencies, whereas TF-IDF captures word importance efficiently.\n",
    "\n",
    "- **Conclusion: When to Use Which Model?**\n",
    "Use SVM (TF-IDF) for fast & high-accuracy sentiment classification.\n",
    "Use GRU/LSTM when text has complex dependencies (e.g., conversational AI, longer text reviews).\n",
    "Use trainable embeddings (instead of pre-trained GloVe) for deep learning models if the dataset language differs significantly from general corpora. \n",
    "\n",
    "**If computational efficiency and performance are the priorities, GRU with Trainable GloVe embeddings is the best deep learning model for this task. However, given that SVM with TF-IDF outperformed both (~95.75% accuracy), it suggests that traditional machine learning models with strong text feature extraction can sometimes be more effective than deep learning models in structured sentiment analysis tasks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026946ea-3eae-4100-9b2c-7106b1cb1857",
   "metadata": {},
   "source": [
    "**Text Cell 11:Acknowledge if you have used any GenAI tools in this assignment and anyone you have worked with on this assignment.** \n",
    "\n",
    "**<span style=\"color:GREEN;\">Acknowledgment</span>**\n",
    " \r",
    "I acknowledge that I have used ChatGPT as a GenAI tool to assist with this assignment. It helped in understanding deep learning concepts, specifically the differences between GRU and LSTM models, as well as pre-trained vs. trainable GloVe embeddings. Additionally, ChatGPT provided guidance on structuring Python code, debugging errors, and comparing model performances effectively. While I leveraged this tool for clarification and optimization, all implementations and final analyses were reviewed and understood by me. Furthermore, I confirm that I worked independently on this assignment and did not collaborate with any classmates or external individuals.e\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2947262-84c4-4250-8b30-891d092d0495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in c:\\users\\balbi\\anaconda\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: notebook in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter) (7.0.8)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter) (7.10.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter) (6.28.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter) (7.8.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (8.25.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipywidgets->jupyter) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipywidgets->jupyter) (3.6.6)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipywidgets->jupyter) (1.0.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-console->jupyter) (3.0.43)\n",
      "Requirement already satisfied: pygments in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-console->jupyter) (2.15.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from notebook->jupyter) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from notebook->jupyter) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from notebook->jupyter) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from notebook->jupyter) (0.2.3)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\balbi\\anaconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.18.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\balbi\\anaconda\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (305.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.4.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyterlab<4.1,>=4.0.2->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyterlab<4.1,>=4.0.2->notebook->jupyter) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.32.2)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\balbi\\anaconda\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\balbi\\anaconda\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2024.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2024.6.2)\n",
      "Requirement already satisfied: executing in c:\\users\\balbi\\anaconda\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\balbi\\anaconda\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\balbi\\anaconda\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: fqdn in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\balbi\\anaconda\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in c:\\users\\balbi\\anaconda\\lib\\site-packages (7.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (5.9.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (23.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (2.15.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (1.2.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbconvert) (5.14.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\balbi\\anaconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (305.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbclient>=0.5.0->nbconvert) (8.6.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbformat>=5.7->nbconvert) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from nbformat>=5.7->nbconvert) (4.19.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from beautifulsoup4->nbconvert) (2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\balbi\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "[NbConvertApp] Converting notebook   LA4_Singh_Balbir.ipynb to html\n",
      "[NbConvertApp] Writing 362339 bytes to   LA4_Singh_Balbir.html\n"
     ]
    }
   ],
   "source": [
    "# Code Cell 12:Render HTML output for this assignment and make sure the output of each cell is shown. \n",
    "# HTML rendering\n",
    "!pip install jupyter\n",
    "!pip install nbconvert\n",
    "!jupyter nbconvert \"  LA4_Singh_Balbir.ipynb\" --to html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
